from flask import Flask, render_template, redirect, request, jsonify
import random
import subprocess
import signal
import datetime
import os

# â”€â”€ LSTM ê´€ë ¨ ìž„í¬íŠ¸ ì¶”ê°€ â”€â”€
import joblib
import numpy as np
from collections import deque

app = Flask(__name__)

# â”€â”€ ê¸°ì¡´ ì „ì—­ ë³€ìˆ˜ â”€â”€
socket_data = {}
charging = 2
test_socket_process = None
connector_stat = True
stat = ""
enable = False

Car_stat: dict = {
    "VIN" : "", #Car vin info
    "Model" : "", #Car model info
    "Connect" : "ì»¤ë„¥í„° ì—°ê²° í•´ì œë¨", #Default connector stat
    "Alert" : False #Modal alram stat
}

# í˜„ìž¬ íŒŒì¼(__file__) ìœ„ì¹˜: Env/Web/main.py
BASE_DIR = os.path.dirname(os.path.dirname(os.path.abspath(__file__)))  # â†’ Env í´ë”
MODEL_DIR = os.path.join(BASE_DIR, "LSTM", "models")
LSTM_MODEL_PATH = os.path.join(MODEL_DIR, "lstm_pred.h5")
SCALER_PATH     = os.path.join(MODEL_DIR, "scaler.pkl")
THRESHOLD_PATH  = os.path.join(MODEL_DIR, "threshold.npy")
# ë¯¸ë¦¬ ë¡œë“œ
try:
    import tensorflow as tf
    lstm_model = tf.keras.models.load_model(LSTM_MODEL_PATH, compile=False)
    scaler = joblib.load(SCALER_PATH)
    threshold = float(np.load(THRESHOLD_PATH))
    print(f"[LSTM] ëª¨ë¸, ìŠ¤ì¼€ì¼ëŸ¬, threshold ë¡œë“œ ì™„ë£Œ (threshold={threshold:.6f})")
except Exception as e:
    print(f"[LSTM] ëª¨ë¸ ë¡œë“œ ì‹¤íŒ¨: {e}")
    lstm_model = None
    scaler = None
    threshold = None

# ì‹œí€€ìŠ¤ ê¸¸ì´ì™€ í”¼ì²˜ ì„¤ì •
SEQ_LEN = 120
FEATURE_KEYS = ["Voltage_terminal", "SOC", "Temperature", "Charge_Current"]
FEATURE_DIM = len(FEATURE_KEYS)

# ê³ ì • ê¸¸ì´ ë²„í¼ ìƒì„±
buffer_deque = deque(maxlen=SEQ_LEN)
@app.route('/') #main page router
def index():
    global socket_data
    global connector_stat
    if charging == 2:
        if(connector_stat):
            Car_stat["VIN"] = ""
            Car_stat["Model"] = ""
            Car_stat["Connect"] = "ðŸ”Œ ì»¤ë„¥í„° ì—°ê²° í•´ì œë¨"
            connector_stat = False
            stat = "ðŸ”Œ ì¶©ì „ê¸° ì—°ê²° í•„ìš”"
        else:
            Car_stat["VIN"] = "0x12345678"
            Car_stat["Model"] = "ðŸš˜ Ionic 5"
            Car_stat["Connect"] = "ðŸ”Œ ì»¤ë„¥í„° ì—°ê²°ë¨"
            connector_stat = True
            stat = "ðŸŸ  ì¶©ì „ ëŒ€ê¸°"
    elif charging == 1:
        if(connector_stat):
            stat = "ðŸŸ¢ ì¶©ì „ ì¤‘" #ì¶”í›„ ì•„ì´ì½˜ ì¶”ê°€ ì˜ˆì •
        else:
            stat = "ðŸ”Œ ì¶©ì „ê¸° ì—°ê²° í•„ìš”"
            Car_stat["Alert"] = True
    elif charging == 0:
        stat = "ðŸ”´ ì¶©ì „ ì¤‘ë‹¨"
    return render_template('index.html',datas=stat,info=Car_stat, data=socket_data) #Use template load index.html

@app.route("/connector", methods = ['POST'])
def connector(): #if connected connector -> used this
    global charging
    charging = 2
    return redirect('/')

@app.route('/start', methods=['POST'])  # ì¶©ì „ ì‹œìž‘ ë²„íŠ¼
def start():
    global charging, test_socket_process, enable
    charging = 1  # ì¶©ì „ ì¤‘ ìƒíƒœë¡œ ì „í™˜
    if enable == False:
        try:
            print("[DEBUG] Launching testsocket.py...")
            path = os.path.join(os.getcwd(), "testsocket.py")
            # print(f"[DEBUG] Full path: {path}")
            test_socket_process = subprocess.Popen(["python3", path])
            enable = True
        except Exception as e:
            print(f"[ERROR] Failed to launch testsocket.py: {e}")
    else:
        print("ì´ë¯¸ ì‹¤í–‰ì¤‘")
    return redirect('/') #Click the ì¶©ì „ ì‹œìž‘ button will redirect to the main

@app.route('/stop', methods=['POST'])
def stop():
    global charging, test_socket_process,socket_data, enable
    charging = 0  # ì¶©ì „ ì¤‘ë‹¨ ìƒíƒœë¡œ ì „í™˜
    socket_data={}
    enable = False
    if test_socket_process is not None:
        test_socket_process.send_signal(signal.SIGINT)
        test_socket_process.wait(timeout=5)
        test_socket_process = None

    return redirect('/') #Click the ì¶©ì „ ì¤‘ë‹¨ button will redirect to the main

@app.route('/monitor', methods=['POST']) #monitor page
def monitoring():
    return render_template('monier.html')

@app.route('/update/data', methods=['GET'])
def Senddata():
    return jsonify(socket_data)

@app.route('/update', methods=['POST'])
def Update_data():
    global socket_data, buffer_deque, lstm_model, scaler, threshold

    # 1) ë“¤ì–´ì˜¨ JSON ì €ìž¥
    incoming = request.get_json()
    socket_data = incoming.copy()

    # 2) í”¼ì²˜ ë²¡í„° ìƒì„±
    try:
        feature_vector = np.array([
            float(incoming.get("Voltage_terminal", 0)),
            float(incoming.get("SOC", 0)),
            float(incoming.get("Temperature", 0)),
            float(incoming.get("Charge_Current", 0))
        ], dtype=float)
    except Exception as e:
        print(f"[LSTM] Feature ë²¡í„° ìƒì„± ì˜¤ë¥˜: {e}")
        return jsonify({"status": "invalid data"}), 400

    # 3) ë²„í¼ì— ì¶”ê°€
    buffer_deque.append(feature_vector)

    # 4) ë²„í¼ê°€ ê°€ë“ ì°¨ë©´ ì˜ˆì¸¡ ìˆ˜í–‰
    if (
        lstm_model is not None
        and scaler is not None
        and threshold is not None
        and len(buffer_deque) == SEQ_LEN
    ):
        arr = np.array(buffer_deque)  # shape: (SEQ_LEN, FEATURE_DIM)
        arr_scaled = scaler.transform(arr)
        input_seq = arr_scaled.reshape((1, SEQ_LEN, FEATURE_DIM))

        # LSTM ì˜ˆì¸¡
        pred = lstm_model.predict(input_seq, verbose=0).flatten()
        actual_scaled = scaler.transform(arr[-1:].reshape(1, -1)).flatten()

        # í‰ê·  ì ˆëŒ€ ì˜¤ì°¨ ê³„ì‚°
        err = np.mean(np.abs(pred - actual_scaled))

        if err > threshold:
            print(f"[LSTM][Anomaly] err={err:.6f} > threshold={threshold:.6f}")
            # í•„ìš” ì‹œ ì¶”ê°€ ì²˜ë¦¬ (ì˜ˆ: WebSocketìœ¼ë¡œ STOP_CHARGE ì „ì†¡)

    return jsonify({"status": "received"})

if __name__ == '__main__':
    app.run(host='0.0.0.0', port=9359, debug=False) #debug mode -> Turn off debug EXPO
